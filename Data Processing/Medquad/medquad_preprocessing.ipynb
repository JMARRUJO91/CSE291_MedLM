{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import xmltodict\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from jsonpath import jsonpath\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the preprocess handler function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "}\n",
    "cnt = 0\n",
    "bigErr = 0\n",
    "def processXmlFile(completePath):\n",
    "  with open(completePath) as f:\n",
    "    global cnt, data, bigErr\n",
    "    cnt += 1\n",
    "\n",
    "    xmlstring = f.read()\n",
    "    dataDict = xmltodict.parse(xmlstring, xml_attribs = True)\n",
    "    try:\n",
    "      dataDict = dataDict[\"Document\"]\n",
    "    except:\n",
    "      bigErr += 1\n",
    "      return\n",
    "\n",
    "    # Main topic of ques\n",
    "    try:\n",
    "      topic = dataDict[\"Focus\"] + \"|\"+str(cnt)\n",
    "    except Exception as e:\n",
    "      warnings.warn(\"error in parsing Focus\"+ str(e))\n",
    "      topic = \"UNKNOWN\" + \"|\"+str(cnt)\n",
    "    \n",
    "    # Type of topic\n",
    "    try:\n",
    "      group = dataDict[\"FocusAnnotations\"][\"UMLS\"][\"SemanticGroup\"]\n",
    "    except Exception as e:\n",
    "      warnings.warn(\"error in parsing group/type of topic\"+ str(e))\n",
    "      group = \"UNKNOWN\"\n",
    "    \n",
    "    # Synonyms\n",
    "    try:\n",
    "      synonyms = dataDict[\"FocusAnnotations\"][\"Synonyms\"][\"Synonym\"]\n",
    "    except Exception as e:\n",
    "      warnings.warn(\"error in parsing QA\"+ str(e))\n",
    "      synonyms = []\n",
    "\n",
    "    \n",
    "    try:\n",
    "      QAs_raw = dataDict[\"QAPairs\"][\"QAPair\"]\n",
    "      QAs = []\n",
    "      for QA_i in QAs_raw:\n",
    "        QA = {}\n",
    "        QA[\"type\"] = QA_i[\"Question\"][\"@qtype\"]\n",
    "        QA[\"question\"] = QA_i[\"Question\"][\"#text\"]\n",
    "        QA[\"answer\"] = QA_i[\"Answer\"]\n",
    "        QAs.append(QA)      \n",
    "\n",
    "    except Exception as e:\n",
    "      warnings.warn(\"error in parsing QA\"+ str(e))\n",
    "      QAs = []\n",
    "\n",
    "\n",
    "\n",
    "    data[topic] = {\n",
    "        \"group\":group,\n",
    "        \"synonyms\":synonyms,\n",
    "        \"QAs\":QAs,\n",
    "    }\n",
    "\n",
    "    \n",
    "    '''\n",
    "    for qaPair in listOfQA:\n",
    "      try:\n",
    "        # remove the extra spaces from answer with single space\n",
    "        x = re.sub(' +', ' ', qaPair['Answer'])\n",
    "        x = re.sub('Key Points', \"\", x)\n",
    "        x = x.replace(\"\\n\", \"\").replace(\"-\", \"\")\n",
    "        data['Answers'].append( x )\n",
    "        data['Questions'].append( qaPair['Question'] )\n",
    "        data['Focus'].append(focus)\n",
    "      except:\n",
    "        return\n",
    "        '''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldersWithEmptyAnswers = [\n",
    "  \"10_MPlus_ADAM_QA\", # These three removed due to copyright!\n",
    "    \"11_MPlusDrugs_QA\",\n",
    "    \"12_MPlusHerbsSupplements_QA\",\n",
    "    \"readme.txt\", # As it does not contain any QAs\n",
    "    \"QA-TestSet-LiveQA-Med-Qrels-2479-Answers.zip\", # will use it later,\n",
    "    \"ProcessedData.csv\"\n",
    "]\n",
    "\n",
    "BASE_PATH = \"/content/drive/MyDrive/Group_Project_Shang/Data/MedQuAD-master\"\n",
    "for folder in tqdm(os.listdir(BASE_PATH)):\n",
    "  if folder in foldersWithEmptyAnswers:\n",
    "    continue\n",
    "  else:\n",
    "    print(\"Processing folder:\", folder)\n",
    "    start = time.time()\n",
    "\n",
    "    for xmlFileName in os.listdir( os.path.join(BASE_PATH, folder) ):\n",
    "      completePath = os.path.join(BASE_PATH, folder, xmlFileName)\n",
    "      # print(\"Processing File:\", xmlFileName)\n",
    "      processXmlFile(completePath)\n",
    "      \n",
    "      # print(\"Took\", time.time() - start)\n",
    "print(\"BIG ERRORS\", bigErr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('/content/drive/MyDrive/Group_Project_Shang/Data/medQuad_preprocessed/train.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list(data.keys())[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[list(data.keys())[0]][\"QAs\"][0].keys()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
