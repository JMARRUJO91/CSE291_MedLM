{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: This is a repeat of what we do while running bloom... Just though it also belonged here. We had shared this bloom_train.pkl with some more LLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the preprocessed json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load medQuad preprocessed dataset\n",
    "import json\n",
    "\n",
    "# Open the JSON file\n",
    "with open(\"/content/drive/MyDrive/Group_Project_Shang/Data/medQuad_preprocessed/train.json\", 'r') as f:\n",
    "    # Load the contents of the file into a variable\n",
    "    json_data = f.read()\n",
    "\n",
    "# Parse the JSON data into a Python dictionary\n",
    "dataset_raw = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset_raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a list of prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = []\n",
    "maxi = []\n",
    "c = 0\n",
    "for k in dataset_raw:\n",
    "  title = \"Title: \" + str(k.split(\"|\")[0])+\"\\n\"\n",
    "  syns = \"Synonyms: \" + \", \".join(dataset_raw[k][\"synonyms\"]) + \"\\n\"\n",
    "  groups = \"Groups: \" + str(dataset_raw[k][\"group\"]) + \"\\n\\n\"\n",
    "\n",
    "  for qa in range(len(dataset_raw[k][\"QAs\"])):\n",
    "    c += 1\n",
    "    typee = \"Title: \" + str(dataset_raw[k][\"QAs\"][qa][\"type\"]) + \"\\n\\n\"\n",
    "    question = \"Question: \" + str(dataset_raw[k][\"QAs\"][qa][\"question\"]) + \"\\n\\n\"\n",
    "    answer = \"Answer: \" + str(dataset_raw[k][\"QAs\"][qa][\"answer\"]) + \"\\n\"\n",
    "    \n",
    "    final = title + syns + groups + typee + question + answer\n",
    "    maxi.append(len(final.split()))\n",
    "      \n",
    "    \n",
    "print(max(maxi))\n",
    "print(np.mean(maxi))\n",
    "print(np.median(maxi))\n",
    "above_230 = [x for x in maxi if x > 500]\n",
    "\n",
    "# Use the len() function to count how many numbers are in the new list\n",
    "count = len(above_230)\n",
    "print(count)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(maxi, bins=50)\n",
    "\n",
    "# Add a vertical line to show the cut-off number\n",
    "plt.axvline(x=500, color='red')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Data with Cut-Off at 40')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "print(\"cnt\",c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = []\n",
    "CUTOFF = 500\n",
    "for k in dataset_raw:\n",
    "  title = \"Title: \" + str(k.split(\"|\")[0])+\"\\n \"\n",
    "  syns = \"Synonyms: \" + \", \".join(dataset_raw[k][\"synonyms\"]) + \"\\n \"\n",
    "  groups = \"Groups: \" + str(dataset_raw[k][\"group\"]) + \"\\n\\n \"\n",
    "\n",
    "  for qa in range(len(dataset_raw[k][\"QAs\"])):\n",
    "    c += 1\n",
    "    typee = \"Type: \" + str(dataset_raw[k][\"QAs\"][qa][\"type\"]) + \"\\n \"\n",
    "    question = \"Question: \" + str(dataset_raw[k][\"QAs\"][qa][\"question\"]) + \"\\n\\n \"\n",
    "    answer = \"Answer: \" + str(dataset_raw[k][\"QAs\"][qa][\"answer\"])\n",
    "    \n",
    "    final = title + syns + groups + typee + question + answer\n",
    "\n",
    "    dataset.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving\n",
    "with open('/content/drive/MyDrive/Group_Project_Shang/Data/medQuad_preprocessed/bloom_train.pkl', 'wb') as f:\n",
    "    # Dump the list using pickle\n",
    "    pickle.dump(dataset, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading\n",
    "with open('/content/drive/MyDrive/Group_Project_Shang/Data/medQuad_preprocessed/bloom_train.pkl', 'rb') as f:\n",
    "    # Load the list using pickle\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "# Print the loaded list\n",
    "print(len(dataset))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
