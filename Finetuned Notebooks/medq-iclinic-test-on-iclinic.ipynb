{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport scipy.spatial\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nfrom torch.utils.data import DataLoader, SequentialSampler, TensorDataset\nimport torch\nimport pandas as pd\nfrom pprint import pprint\n\nimport sys\nimport os\nimport glob\n","metadata":{"id":"QPMeTz6OC6G5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"markdown","source":"### Load iClinic","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_iClinic =pd.read_csv('/kaggle/input/iclinic/iclinic.csv')\ndf_iClinic = df_iClinic.apply(lambda x: x.astype(str).str.lower())\ndf_iClinic = df_iClinic.rename(columns={'Question': 'question'})\ndf_iClinic = df_iClinic.rename(columns={'Answer': 'answer'})\ndf_iClinic = df_iClinic.apply(lambda x: x.astype(str).str.lower())\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf_iClinic_train, df_iClinic_test = train_test_split(df_iClinic, test_size=0.1, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_iClinic)\nprint(df_iClinic.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load MedQuad","metadata":{"id":"DxqXHY-KMyHO"}},{"cell_type":"code","source":"PATH = '/kaggle/input/medquad/MedQuad_train.json'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd\n# Open the JSON file\nwith open(PATH, 'r') as f:\n    # Load the contents of the file into a variable\n    json_data = f.read()\n\n# Parse the JSON data into a Python dictionary\ndataset_raw = json.loads(json_data)\n\nimport numpy as np\ndf = []\nfor k in dataset_raw:\n  for qa in range(len(dataset_raw[k][\"QAs\"])):\n    question =  str(dataset_raw[k][\"QAs\"][qa][\"question\"])\n    answer =  str(dataset_raw[k][\"QAs\"][qa][\"answer\"])\n    # if len(answer.split()) < 300:\n    final = {\"question\": question, \"answer\": answer}\n    df.append(final)\ndf = pd.DataFrame(df)\ndf = df.apply(lambda x: x.astype(str).str.lower())","metadata":{"id":"eGecR4QTMsJj","outputId":"c37ee9ee-ffbc-4a64-f0c0-ffc11f952027","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df  = df.append(df_iClinic_train, ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q_list = \"question: \" + df['question']                          # questions list to feed the model\nn_list = df['answer'] + \" </s>\"  # answers list to feed the model\n\ndict_data = {'source_text': q_list,\n      'target_text': n_list}\n\ndf = pd.DataFrame(dict_data)\ndf.head()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q_list = \"question: \" + df_iClinic_test['question']                          # questions list to feed the model\nn_list = df_iClinic_test['answer'] + \" </s>\"  # answers list to feed the model\n\ndict_data = {'source_text': q_list,\n      'target_text': n_list}\n\ndf_iClinic_test = pd.DataFrame(dict_data)\ndf_iClinic_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade simplet5","metadata":{"id":"kuAGZUBiPoMj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **T5 extract the answer from the question, so here we should feed the model with the question and the exact answer/s.**","metadata":{"id":"fOhk6rOEdptA"}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['source_text'][0]","metadata":{"id":"xjWZkMTfqsd7","outputId":"c4d0369b-037b-488d-98cf-8e03695eaa48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target_text'][0]","metadata":{"id":"j965hYhQqsfv","outputId":"be71b917-d0d0-4188-e186-d140ea94fc67","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape, len(df.source_text.unique()), len(df.target_text.unique())","metadata":{"id":"79vuVmsxQ0vp","outputId":"4f0ee54a-d62f-4b84-ca41-950e3949e3ba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting data into train and test data\ntrain_data, val_data = train_test_split(df[:-100], test_size=0.0001)\ntrain_data.shape, val_data.shape, df_iClinic_test.shape","metadata":{"id":"pIm47xqRsjgO","outputId":"9f87dcf7-205e-41d2-c42d-a5655c1c3300","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom simplet5 import SimpleT5\n\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-small\")\nmodel.train(train_df = train_data,\n            eval_df = val_data, \n            source_max_token_len=200, \n            target_max_token_len=512, \n            batch_size=16, max_epochs=3, use_gpu=True)","metadata":{"id":"Dl2rcvYNtSn-","outputId":"c4fb78c8-3566-4c5b-d428-bcae39ed13bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ll ./outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mv \"./outputs/simplet5-epoch-2-train-loss-3.0615-val-loss-2.9346\" \"./outputs/simplet5-iclinic+medq-epoch-3\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stored at ./outputs/simplet5-epoch-3","metadata":{}},{"cell_type":"code","source":"model.load_model(\"t5\",\"./outputs/simplet5-iclinic+medq-epoch-3\", use_gpu=True)# only medquad","metadata":{"id":"x6ojUuzxt2J0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_iClinic_test['source_text']","metadata":{"id":"_RQzauCQ3Vca","outputId":"fb470d3c-2e2a-4d6e-925f-13cb5c62fea5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample","metadata":{}},{"cell_type":"code","source":"q_test = df_iClinic_test['source_text'][2222]\nq_ans = df_iClinic_test['target_text'][2222]\n\nprint(\"Question: \", q_test)\nprint('-'*50)\nprint(\"Answer: \",q_ans)","metadata":{"id":"dzBN-KXTux_A","outputId":"f85197a6-8f3c-4dc3-f8be-84c954aef31a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_ans = model.predict(q_test)[0]\n\nprint(predicted_ans)","metadata":{"id":"NBaxLdobvwME","outputId":"edf39378-00fc-4c65-e32c-19f32e7a1f39","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n","metadata":{}},{"cell_type":"markdown","source":"# Evaluation data","metadata":{"id":"alDbpH4lBcKL"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass QADatasetTest(Dataset):\n    def __init__(self, data, tokenizer, max_len_out_test=512):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.max_len_out_test = max_len_out_test\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        question = self.data.loc[idx, 'source_text']\n        inputs = self.tokenizer.encode_plus(\n            question,\n            truncation=True,\n            padding='max_length' ,\n            max_length=512,\n            return_tensors='pt'  \n        )\n        return {\n            'input_ids': inputs.input_ids.flatten(),\n            'attention_mask': inputs.attention_mask.flatten()\n        }\nbatch_size = 78  # Specify the desired batch size\ndf_iClinic_test = df_iClinic_test.reset_index()\ntest_dataset = QADatasetTest(df_iClinic_test, model.tokenizer, max_len_out_test=512)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n\n# num_batches = len(test_data) // batch_size\n\n# Initialize the predicted answers list\ny_pred = []\n\n\ndef predict(\n        dl,\n        max_length: int = 512,\n        num_return_sequences: int = 1,\n        num_beams: int = 3,\n        top_k: int = 40,\n        top_p: float = 0.95,\n        do_sample: bool = True,\n        repetition_penalty: float = 30.5,\n        length_penalty: float = 1.0,\n        early_stopping: bool = True,\n        skip_special_tokens: bool = True,\n        clean_up_tokenization_spaces: bool = True,\n    ):\n    device = torch.device(\"cuda\")\n    for batch in tqdm(test_dataloader, desc=\"Testing progress\", unit=\"batch\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        generated_ids = model.model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            num_beams=num_beams,\n            max_length=max_length,\n            repetition_penalty=repetition_penalty,\n            length_penalty=length_penalty,\n            early_stopping=early_stopping,\n            top_p=top_p,\n            top_k=top_k,\n            num_return_sequences=num_return_sequences,\n        )\n#         print(generated_ids.shape, flush=True)\n        preds =model.tokenizer.batch_decode(\n                generated_ids,\n                skip_special_tokens=skip_special_tokens,\n                clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n            )\n\n        y_pred.extend(preds)\n    return y_pred\n    \ny_pred = predict(test_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing specific answers","metadata":{}},{"cell_type":"code","source":"# import pickle\n\n# with open('/kaggle/input/medquadsubset/test_queses.pickle', 'rb') as file:\n#     loaded_dict = pickle.load(file)\n# # shuffled_test_data = test_data.iloc[indices]\n# loaded_dict\n# with open('/kaggle/input/medquadsubset/test_answers.pickle', 'rb') as file:\n#     loaded_ans_dict = pickle.load(file)\n# # shuffled_test_data = test_data.iloc[indices]\n# loaded_ans_dict\n# data = {'source_text': loaded_dict, 'target_text': loaded_ans_dict}\n# indices = [61,9,59,71,43]\n# shuffled_test_data = pd.DataFrame(data).iloc[indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_iClinic_test[\"source_text\"][71]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 78  # Specify the desired batch size\n# shuffled_test_data = shuffled_test_data.reset_index()\n# test_dataset = QADatasetTest(shuffled_test_data, model.tokenizer, max_len_out_test=512)\n# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n# y_pred = []\n# y_pred = predict(test_dataloader)\n# shuffled_test_data[\"source_text\"]\n# y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_list_to_file(data_list,questions, file_path):\n    with open(file_path, 'w') as file:\n        i=0\n        for item in data_list:\n            file.write(item + '\\n')\n            file.write(questions[i] + '\\n')\n            i=i+1\nsave_list_to_file(y_pred,df_iClinic_test[\"source_text\"], './outputs/new_data_predicted_output_MedQuad+iclinic_test_iClinic.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = df_iClinic_test[\"target_text\"].to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_odd_lines_to_list(file_path):\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n        odd_lines = [line.strip() for i, line in enumerate(lines) if i % 2 != 0]\n    return odd_lines\nfile_path = './outputs/new_data_predicted_output_MedQuad+iclinic_test_iClinic.txt'\ny_pred = read_odd_lines_to_list(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=2\nprint(\"Predicted: \",y_pred[i])\nprint(\"actual : \",y_test[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [BLEU SCORE](https://www.journaldev.com/46659/bleu-score-in-python)","metadata":{"id":"fBnx8fbjl1d7"}},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu","metadata":{"id":"nQUBS4dbl3Vg","outputId":"d575f3cc-9aa5-4b04-9ca7-5862f30b32fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [ROUGE score ](https://pypi.org/project/rouge-score/)","metadata":{"id":"59vsRyvbnnwG"}},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"id":"nZs1CGudn7S3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation ALL","metadata":{}},{"cell_type":"code","source":"!pip install rouge-score\n!pip install nltk\n!pip install rouge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.tokenize import  word_tokenize\nimport nltk\nimport numpy as np\nfrom rouge import Rouge\nnltk.download('punkt')\ndf_iClinic_test[\"preds\"]=y_pred\n\ndef bleu1(reference_captions, predicted_caption):\n    return 100 * sentence_bleu(reference_captions, predicted_caption,\n                               weights=(1, 0, 0, 0), smoothing_function=SmoothingFunction().method1)\n\n\ndef bleu4(reference_captions, predicted_caption):\n    return 100 * sentence_bleu(reference_captions, predicted_caption,\n                               weights=(0, 0, 0, 1), smoothing_function=SmoothingFunction().method1)\n\nrouge = Rouge()\n\n# pred_caption = word_tokenize(pred_caption.lower())\n\nground_truth = y_test\ngenerated_ans = y_pred\n\nBleu1 = []\nBleu4 = []\nrouge_1_score = []\nrouge_2_score = []\nrouge_L_score = []\n\nfor i in range(len(ground_truth)):\n    grndAns = ground_truth[i]\n    gen_ans = generated_ans[i]\n    \n    # BLEU SCORES\n    gen_ans_ = word_tokenize(gen_ans.lower())\n    grndAns_ = word_tokenize(grndAns.lower())\n    bleu1s = bleu1(grndAns_, gen_ans_)\n    bleu4s = bleu4(grndAns_, gen_ans_)\n    Bleu1.append(bleu1s)\n    Bleu4.append(bleu4s)\n    \n    # Rouge\n    scores = rouge.get_scores(gen_ans, grndAns)\n    r1s = scores[0]['rouge-1']['f'] # f1 score\n    r2s = scores[0]['rouge-2']['f']\n    rLs = scores[0]['rouge-l']['f']\n    rouge_1_score.append(r1s)\n    rouge_2_score.append(r2s)\n    rouge_L_score.append(rLs)\n    \n\nprint(\"BLEU 1 Gram: \", np.mean(Bleu1))\nprint(\"BLEU 4 Gram: \", np.mean(Bleu4))\nprint(\"ROUGE 1 Gram:\", np.mean(rouge_1_score))\nprint(\"ROUGE 2 Gram:\", np.mean(rouge_2_score))\nprint(\"ROUGE L Gram:\", np.mean(rouge_L_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}