{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport scipy.spatial\nimport matplotlib.pyplot as plt\n\n\n# from transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nfrom torch.utils.data import DataLoader, SequentialSampler, TensorDataset\nimport torch\nimport pandas as pd\nfrom pprint import pprint\n\nimport sys\nimport os\nimport glob\n","metadata":{"id":"QPMeTz6OC6G5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"df_iClinic =pd.read_csv('/kaggle/input/iclinic/iclinic.csv')\ndf_iClinic = df_iClinic.apply(lambda x: x.astype(str).str.lower())\ndf_iClinic = df_iClinic.rename(columns={'Question': 'question'})\ndf_iClinic = df_iClinic.rename(columns={'Answer': 'answer'})\ndf_iClinic = df_iClinic.apply(lambda x: x.astype(str).str.lower())\n\nq_list = \"question: \" + df_iClinic['question']                          # questions list to feed the model\nn_list = df_iClinic['answer'] + \" </s>\"  # answers list to feed the model\n\ndict_data = {'source_text': q_list,\n      'target_text': n_list}\n\ndf = pd.DataFrame(dict_data)\ndf.head() \n\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf_iClinic_train, df_iClinic_test = train_test_split(df, test_size=0.1, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_iClinic_train)\nprint(df_iClinic_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade simplet5","metadata":{"id":"kuAGZUBiPoMj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **T5 extract the answer from the question, so here we should feed the model with the question and the exact answer/s.**","metadata":{"id":"fOhk6rOEdptA"}},{"cell_type":"code","source":"df_iClinic_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['source_text'][0]","metadata":{"id":"xjWZkMTfqsd7","outputId":"c4d0369b-037b-488d-98cf-8e03695eaa48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target_text'][0]","metadata":{"id":"j965hYhQqsfv","outputId":"be71b917-d0d0-4188-e186-d140ea94fc67","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Split","metadata":{}},{"cell_type":"code","source":"# splitting data into train and test data\ndf_iClinic_train, df_iClinic_val = train_test_split(df_iClinic_train[:-100], test_size=0.0001)\ndf_iClinic_train.shape, df_iClinic_val.shape, df_iClinic_test.shape","metadata":{"id":"pIm47xqRsjgO","outputId":"9f87dcf7-205e-41d2-c42d-a5655c1c3300","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Model Up","metadata":{}},{"cell_type":"code","source":"%%time\nfrom simplet5 import SimpleT5\n\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-small\")\nmodel.train(train_df = df_iClinic_train,\n            eval_df = df_iClinic_val, \n            source_max_token_len=200, \n            target_max_token_len=200, \n            batch_size=40, max_epochs=3, use_gpu=True)","metadata":{"id":"Dl2rcvYNtSn-","outputId":"c4fb78c8-3566-4c5b-d428-bcae39ed13bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ll ./outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stored at ./outputs/simplet5-epoch-3","metadata":{}},{"cell_type":"code","source":"# loading the trained model for inferencing\nmodel.load_model(\"t5\",\"./outputs/simplet5-iclinic-epoch-3\", use_gpu=True)# only medquad","metadata":{"id":"x6ojUuzxt2J0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample Test","metadata":{}},{"cell_type":"code","source":"q_test = df_iClinic_test['source_text'][2222]\nq_ans = df_iClinic_test['target_text'][2222]\n\nprint(\"Question: \", q_test)\nprint('-'*50)\nprint(\"Answer: \",q_ans)","metadata":{"id":"dzBN-KXTux_A","outputId":"f85197a6-8f3c-4dc3-f8be-84c954aef31a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_ans = model.predict(q_test)[0]\n\nprint(predicted_ans)","metadata":{"id":"NBaxLdobvwME","outputId":"edf39378-00fc-4c65-e32c-19f32e7a1f39","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass QADatasetTest(Dataset):\n    def __init__(self, data, tokenizer, max_len_out_test=512):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.max_len_out_test = max_len_out_test\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        question = self.data.loc[idx, 'source_text']\n        inputs = self.tokenizer.encode_plus(\n            question,\n            truncation=True,\n            padding='max_length' ,\n            max_length=512,\n            return_tensors='pt'  \n        )\n        return {\n            'input_ids': inputs.input_ids.flatten(),\n            'attention_mask': inputs.attention_mask.flatten()\n        }\nbatch_size = 78  # Specify the desired batch size\ndf_iClinic_test = df_iClinic_test.reset_index()\ntest_dataset = QADatasetTest(df_iClinic_test, model.tokenizer, max_len_out_test=512)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n\n# Initialize the predicted answers list\ny_pred = []\n\n\ndef predict(\n        dl,\n        max_length: int = 512,\n        num_return_sequences: int = 1,\n        num_beams: int = 3,\n        top_k: int = 40,\n        top_p: float = 0.95,\n        do_sample: bool = True,\n        repetition_penalty: float = 30.5,\n        length_penalty: float = 1.0,\n        early_stopping: bool = True,\n        skip_special_tokens: bool = True,\n        clean_up_tokenization_spaces: bool = True,\n    ):\n    device = torch.device(\"cuda\")\n    for batch in tqdm(test_dataloader, desc=\"Testing progress\", unit=\"batch\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        generated_ids = model.model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            num_beams=num_beams,\n            max_length=max_length,\n            repetition_penalty=repetition_penalty,\n            length_penalty=length_penalty,\n            early_stopping=early_stopping,\n            top_p=top_p,\n            top_k=top_k,\n            num_return_sequences=num_return_sequences,\n        )\n        preds =model.tokenizer.batch_decode(\n                generated_ids,\n                skip_special_tokens=skip_special_tokens,\n                clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n            )\n\n        y_pred.extend(preds)\n    return y_pred\n    \ny_pred = predict(test_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_list_to_file(data_list,questions, file_path):\n    with open(file_path, 'w') as file:\n        i=0\n        for item in data_list:\n            file.write(item + '\\n')\n            file.write(questions[i] + '\\n')\n            i=i+1\nsave_list_to_file(y_pred,df_iClinic_test[\"source_text\"], './outputs/new_data_predicted_output_iclinic_test_iclinic.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = df_iClinic_test[\"target_text\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [BLEU SCORE](https://www.journaldev.com/46659/bleu-score-in-python)","metadata":{"id":"fBnx8fbjl1d7"}},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu","metadata":{"id":"nQUBS4dbl3Vg","outputId":"d575f3cc-9aa5-4b04-9ca7-5862f30b32fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [ROUGE score ](https://pypi.org/project/rouge-score/)","metadata":{"id":"59vsRyvbnnwG"}},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"id":"nZs1CGudn7S3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation ALL","metadata":{}},{"cell_type":"code","source":"!pip install rouge-score\n!pip install nltk\n!pip install rouge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.tokenize import  word_tokenize\nimport nltk\nimport numpy as np\nfrom rouge import Rouge\nnltk.download('punkt')\ndf_iClinic_test[\"preds\"]=y_pred\n\ndef bleu1(reference_captions, predicted_caption):\n    return 100 * sentence_bleu(reference_captions, predicted_caption,\n                               weights=(1, 0, 0, 0), smoothing_function=SmoothingFunction().method1)\n\n\ndef bleu4(reference_captions, predicted_caption):\n    return 100 * sentence_bleu(reference_captions, predicted_caption,\n                               weights=(0, 0, 0, 1), smoothing_function=SmoothingFunction().method1)\n\nrouge = Rouge()\n\nground_truth = y_test.values.tolist()\ngenerated_ans = y_pred\n\nBleu1 = []\nBleu4 = []\nrouge_1_score = []\nrouge_2_score = []\nrouge_L_score = []\n\nfor i in range(len(ground_truth)):\n    grndAns = ground_truth[i]\n    gen_ans = generated_ans[i]\n    \n    # BLEU SCORES\n    gen_ans_ = word_tokenize(gen_ans.lower())\n    grndAns_ = word_tokenize(grndAns.lower())\n    bleu1s = bleu1(grndAns_, gen_ans_)\n    bleu4s = bleu4(grndAns_, gen_ans_)\n    Bleu1.append(bleu1s)\n    Bleu4.append(bleu4s)\n    \n    # Rouge\n    scores = rouge.get_scores(gen_ans, grndAns)\n    r1s = scores[0]['rouge-1']['f'] # f1 score\n    r2s = scores[0]['rouge-2']['f']\n    rLs = scores[0]['rouge-l']['f']\n    rouge_1_score.append(r1s)\n    rouge_2_score.append(r2s)\n    rouge_L_score.append(rLs)\n    \n\nprint(\"BLEU 1 Gram: \", np.mean(Bleu1))\nprint(\"BLEU 4 Gram: \", np.mean(Bleu4))\nprint(\"ROUGE 1 Gram:\", np.mean(rouge_1_score))\nprint(\"ROUGE 2 Gram:\", np.mean(rouge_2_score))\nprint(\"ROUGE L Gram:\", np.mean(rouge_L_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}